{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T21:14:23.527875Z",
     "iopub.status.busy": "2021-02-09T21:14:23.527366Z",
     "iopub.status.idle": "2021-02-09T21:14:24.163942Z",
     "shell.execute_reply": "2021-02-09T21:14:24.163420Z",
     "shell.execute_reply.started": "2021-02-09T21:14:23.527753Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.parsing.preprocessing import preprocess_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-18T22:06:14.155087Z",
     "iopub.status.busy": "2021-03-18T22:06:14.154823Z",
     "iopub.status.idle": "2021-03-18T22:06:14.158716Z",
     "shell.execute_reply": "2021-03-18T22:06:14.157891Z",
     "shell.execute_reply.started": "2021-03-18T22:06:14.155017Z"
    },
    "tags": []
   },
   "source": [
    "This notebook reads data from `data/{website}/unprocessed/` and writes to `data/{website}/texts/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T21:14:24.164908Z",
     "iopub.status.busy": "2021-02-09T21:14:24.164740Z",
     "iopub.status.idle": "2021-02-09T21:14:24.167376Z",
     "shell.execute_reply": "2021-02-09T21:14:24.166822Z",
     "shell.execute_reply.started": "2021-02-09T21:14:24.164889Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = Path('../../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T21:14:24.168521Z",
     "iopub.status.busy": "2021-02-09T21:14:24.168338Z",
     "iopub.status.idle": "2021-02-09T21:14:24.178030Z",
     "shell.execute_reply": "2021-02-09T21:14:24.177520Z",
     "shell.execute_reply.started": "2021-02-09T21:14:24.168499Z"
    }
   },
   "outputs": [],
   "source": [
    "def process_html(t):\n",
    "    t = t.lower()\n",
    "    t = re.sub(r'\\n', '', t) # replace code\n",
    "    t = re.sub(r'<code>.*?</code>', ' codesnippet ', t) # replace code\n",
    "    t = re.sub(r'<a.*?https?:\\/\\/.*?[\\b\\s]?>', ' url ', t) # replace urls\n",
    "    t = re.sub(r'https?:\\/\\/.*?(?:[\\b\\s]|$)', ' url ', t) # replace urls\n",
    "    t = re.sub(r'<img.*?>', ' img ', t) # replace urls\n",
    "    t = BeautifulSoup(t, features=\"lxml\").get_text()    # remove html tags (better than gensim)\n",
    "\n",
    "    return t\n",
    "\n",
    "def preprocess_table(df):\n",
    "    print('\\t\\t- Removing NaNs')\n",
    "    df.dropna(subset=['text'], inplace=True)\n",
    "    print('\\t\\t- Removing HTML tags, URLs')\n",
    "    df['text']  = df['text'].apply(process_html)\n",
    "    print('\\t\\t- Tokenizing, stemming')\n",
    "    df['words'] = df['text'].apply(preprocess_string)\n",
    "    \n",
    "def remove_foreign_text(ts):\n",
    "    foreign_qids = ts['questions'][ts['questions']['section'].isin(['Japanese', 'Chinese', 'Korean'])]['id']\n",
    "\n",
    "    ts['questions'] = ts['questions'][~ts['questions']['id'].isin(foreign_qids)].copy()\n",
    "    ts['answers'] = ts['answers'][~ts['answers']['question_id'].isin(foreign_qids)].copy()\n",
    "    ts['comments']  = ts['comments'][~ts['comments']['question_id'].isin(foreign_qids)].copy()\n",
    "\n",
    "def preprocess_texts(db_name):\n",
    "    print(f'Preprocessing texts for {db_name}')\n",
    "    \n",
    "    table_names = ['questions', 'answers', 'comments']\n",
    "    tables = {t: pd.read_parquet(data_path / f'{db_name}/unprocessed/{t}.parquet') for t in table_names}\n",
    "    \n",
    "    if db_name == 'ue4':\n",
    "        remove_foreign_text(tables)\n",
    "    \n",
    "    tables['questions']['text'] = tables['questions']['title'] + ' ' + tables['questions']['text']\n",
    "    \n",
    "    tables['questions'] = tables['questions'][['id', 'text']]\n",
    "    tables['answers'] = tables['answers'][['id', 'text']]\n",
    "    tables['comments'] = tables['comments'][['id', 'text']]\n",
    "    \n",
    "    for name, table in tables.items():\n",
    "        print(f'\\t- Processing text for table {name}')\n",
    "        preprocess_table(table)\n",
    "        table.to_parquet(data_path / f'{db_name}'/ 'texts' / f'{name}.parquet')\n",
    "        \n",
    "    tables['questions']['post_type'] = 'question'\n",
    "    tables['answers']['post_type']   = 'answer'\n",
    "    tables['comments']['post_type']  = 'comment'\n",
    "    pd.concat(tables.values()).to_parquet(data_path / f'{db_name}'/ 'texts' / 'corpus.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T21:14:24.179280Z",
     "iopub.status.busy": "2021-02-09T21:14:24.179096Z",
     "iopub.status.idle": "2021-02-09T21:14:24.182010Z",
     "shell.execute_reply": "2021-02-09T21:14:24.181385Z",
     "shell.execute_reply.started": "2021-02-09T21:14:24.179255Z"
    }
   },
   "outputs": [],
   "source": [
    "websites = ['unity', 'ue4', 'stackoverflow', 'gamedev_se']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-27T23:22:52.841499Z",
     "start_time": "2020-10-27T23:07:58.418531Z"
    },
    "execution": {
     "iopub.execute_input": "2021-02-09T21:14:24.617365Z",
     "iopub.status.busy": "2021-02-09T21:14:24.617212Z",
     "iopub.status.idle": "2021-02-09T21:43:03.384029Z",
     "shell.execute_reply": "2021-02-09T21:43:03.383347Z",
     "shell.execute_reply.started": "2021-02-09T21:14:24.617341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing texts for unity\n",
      "\t- Processing text for table questions\n",
      "\t\t- Removing NaNs\n",
      "\t\t- Removing HTML tags, URLs\n",
      "\t\t- Tokenizing, stemming\n",
      "\t- Processing text for table answers\n",
      "\t\t- Removing NaNs\n",
      "\t\t- Removing HTML tags, URLs\n",
      "\t\t- Tokenizing, stemming\n",
      "\t- Processing text for table comments\n",
      "\t\t- Removing NaNs\n",
      "\t\t- Removing HTML tags, URLs\n",
      "\t\t- Tokenizing, stemming\n",
      "Preprocessing texts for ue4\n",
      "\t- Processing text for table questions\n",
      "\t\t- Removing NaNs\n",
      "\t\t- Removing HTML tags, URLs\n",
      "\t\t- Tokenizing, stemming\n",
      "\t- Processing text for table answers\n",
      "\t\t- Removing NaNs\n",
      "\t\t- Removing HTML tags, URLs\n",
      "\t\t- Tokenizing, stemming\n",
      "\t- Processing text for table comments\n",
      "\t\t- Removing NaNs\n",
      "\t\t- Removing HTML tags, URLs\n",
      "\t\t- Tokenizing, stemming\n",
      "Preprocessing texts for stackoverflow\n",
      "\t- Processing text for table questions\n",
      "\t\t- Removing NaNs\n",
      "\t\t- Removing HTML tags, URLs\n",
      "\t\t- Tokenizing, stemming\n",
      "\t- Processing text for table answers\n",
      "\t\t- Removing NaNs\n",
      "\t\t- Removing HTML tags, URLs\n",
      "\t\t- Tokenizing, stemming\n",
      "\t- Processing text for table comments\n",
      "\t\t- Removing NaNs\n",
      "\t\t- Removing HTML tags, URLs\n",
      "\t\t- Tokenizing, stemming\n",
      "Preprocessing texts for gamedev_se\n",
      "\t- Processing text for table questions\n",
      "\t\t- Removing NaNs\n",
      "\t\t- Removing HTML tags, URLs\n",
      "\t\t- Tokenizing, stemming\n",
      "\t- Processing text for table answers\n",
      "\t\t- Removing NaNs\n",
      "\t\t- Removing HTML tags, URLs\n",
      "\t\t- Tokenizing, stemming\n",
      "\t- Processing text for table comments\n",
      "\t\t- Removing NaNs\n",
      "\t\t- Removing HTML tags, URLs\n",
      "\t\t- Tokenizing, stemming\n"
     ]
    }
   ],
   "source": [
    "for w in websites:\n",
    "    preprocess_texts(w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
